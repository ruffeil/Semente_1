import streamlit as st
import pandas as pd
import google.generativeai as genai
from openai import OpenAI
import os

# 1. CONFIGURA√á√ÉO GERAL
st.set_page_config(
    page_title="SEMENTE FRAME",
    page_icon="üå±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# 2. CSS (ESTILO DARK MODE)
st.markdown("""
<style>
    .stApp { background-color: #0E1117; color: #E0E0E0; }
    .stButton>button { background-color: #238636; color: white; border: none; border-radius: 6px; }
    .stButton>button:hover { background-color: #2EA043; }
    #MainMenu {visibility: hidden;} 
    footer {visibility: hidden;} 
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# 3. MOTOR DE INTELIG√äNCIA
class SementeBrain:
    def __init__(self):
        try:
            self.openai_key = st.secrets["OPENAI_API_KEY"]
            self.gemini_key = st.secrets["GOOGLE_API_KEY"]
        except Exception:
            st.error("‚ùå Erro: Chaves de API n√£o configuradas corretamente.")
            st.stop()
        
        # Configura Gemini (Ajustado para 1.5-flash para maior compatibilidade)
        if self.gemini_key:
            try:
                genai.configure(api_key=self.gemini_key)
                # Mudan√ßa estrat√©gica de modelo aqui para evitar o Erro 404
                self.gemini_model = genai.GenerativeModel("gemini-1.5-flash")
            except Exception as e:
                st.warning(f"Erro na conex√£o Gemini: {e}")
            
        # Configura OpenAI
        if self.openai_key:
            try:
                self.openai_client = OpenAI(api_key=self.openai_key)
            except Exception as e:
                st.warning(f"Erro na conex√£o OpenAI: {e}")

    def get_summary(self, df):
        return f"Linhas: {len(df)} | Colunas: {list(df.columns)} | Tipos: {df.dtypes.to_dict()}"

    def ask_gpt(self, prompt, context):
        if not hasattr(self, 'openai_client'): return "‚ö†Ô∏è M√≥dulo de IA indispon√≠vel."
        try:
            res = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Contexto: {context}. Voc√™ √© a Semente do Conhecimento, especialista em engenharia de dados."},
                    {"role": "user", "content": prompt}
                ]
            )
            return res.choices[0].message.content
        except Exception as e: return f"Erro no chat: {e}"

    def get_report(self, context):
        if not hasattr(self, 'gemini_model'): return "‚ö†Ô∏è M√≥dulo de relat√≥rio indispon√≠vel."
        try:
            # Prompt focado em an√°lise t√©cnica
            prompt = f"Aja como a Semente do Conhecimento. Gere um relat√≥rio t√©cnico detalhado sobre estes dados: {context}. Estruture com Diagn√≥stico, Limpeza e Recomenda√ß√µes."
            response = self.gemini_model.generate_content(prompt)
            return response.text
        except Exception as e: 
            return f"‚ùå Erro na gera√ß√£o do relat√≥rio: {e}. Tente novamente em instantes."

# 4. INTERFACE
def main():
    with st.sidebar:
        st.title("üå± SEMENTE FRAME")
        st.caption("v1.2.0 | Semente do Conhecimento")
        st.divider()
        file = st.file_uploader("Carregar Base de Dados (CSV)", type=["csv"])
        st.info("üîí Conex√£o Segura Ativa")

    if file:
        if "df" not in st.session_state:
            st.session_state.df = pd.read_csv(file)
            st.session_state.brain = SementeBrain()
            st.session_state.ctx = st.session_state.brain.get_data_summary(st.session_state.df)
            st.session_state.msgs = [{"role": "assistant", "content": "Ol√°! Sou a Semente do Conhecimento. Seus dados est√£o prontos. O que vamos descobrir hoje?"}]

        for msg in st.session_state.msgs:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        if prompt := st.chat_input("Pergunte √† Semente do Conhecimento..."):
            st.session_state.msgs.append({"role": "user", "content": prompt})
            st.chat_message("user").markdown(prompt)
            with st.spinner("Analisando..."):
                resp = st.session_state.brain.ask_gpt(prompt, st.session_state.ctx)
                st.session_state.msgs.append({"role": "assistant", "content": resp})
                st.chat_message("assistant").markdown(resp)

        st.divider()
        if st.button("üìù Gerar Relat√≥rio T√©cnico"):
            with st.spinner("Semente do Conhecimento auditando dados..."):
                rep = st.session_state.brain.get_report(st.session_state.ctx)
                st.markdown(rep)
    else:
        st.markdown("<br><h1 style='text-align: center'>Bem-vindo ao SEMENTE FRAME üå±</h1>", unsafe_allow_html=True)
        st.markdown("<p style='text-align: center'>Suba um arquivo CSV para iniciar a consultoria autom√°tica.</p>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
