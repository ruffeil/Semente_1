import streamlit as st
import pandas as pd
import google.generativeai as genai
from openai import OpenAI
import os

# 1. CONFIGURA√á√ÉO GERAL
st.set_page_config(
    page_title="SEMENTE FRAME",
    page_icon="üå±",
    layout="wide",
    initial_sidebar_state="expanded"
)

# 2. CSS (ESTILO DARK MODE)
st.markdown("""
<style>
    .stApp { background-color: #0E1117; color: #E0E0E0; }
    .stButton>button { background-color: #238636; color: white; border: none; border-radius: 6px; }
    .stButton>button:hover { background-color: #2EA043; }
    #MainMenu {visibility: hidden;} 
    footer {visibility: hidden;} 
    header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# 3. MOTOR DE INTELIG√äNCIA (AGORA COM SEGREDOS)
class SementeBrain:
    def __init__(self):
        # Tenta carregar dos segredos do Streamlit
        try:
            self.openai_key = st.secrets["OPENAI_API_KEY"]
            self.gemini_key = st.secrets["GOOGLE_API_KEY"]
        except FileNotFoundError:
            st.error("‚ùå ERRO CR√çTICO: Chaves de API n√£o configuradas no servidor.")
            st.stop()
        
        # Configura Gemini
        if self.gemini_key:
            try:
                genai.configure(api_key=self.gemini_key)
                self.gemini_model = genai.GenerativeModel("gemini-1.5-pro")
            except Exception as e:
                st.warning(f"Erro ao conectar Gemini: {e}")
            
        # Configura OpenAI
        if self.openai_key:
            try:
                self.openai_client = OpenAI(api_key=self.openai_key)
            except Exception as e:
                st.warning(f"Erro ao conectar OpenAI: {e}")

    def get_summary(self, df):
        return f"Linhas: {len(df)} | Colunas: {list(df.columns)} | Tipos: {df.dtypes.to_dict()}"

    def ask_gpt(self, prompt, context):
        if not hasattr(self, 'openai_client'): return "‚ö†Ô∏è Sistema de IA offline."
        try:
            res = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": f"Contexto: {context}. Voc√™ √© o Ruffeil, Engenheiro S√™nior."},
                    {"role": "user", "content": prompt}
                ]
            )
            return res.choices[0].message.content
        except Exception as e: return f"Erro no processamento: {e}"

    def get_report(self, context):
        if not hasattr(self, 'gemini_model'): return "‚ö†Ô∏è M√≥dulo de Relat√≥rio offline."
        try:
            return self.gemini_model.generate_content(f"Gere um relat√≥rio t√©cnico executivo sobre: {context}").text
        except Exception as e: return f"Erro na gera√ß√£o: {e}"

# 4. INTERFACE DO USU√ÅRIO (SIMPLIFICADA)
def main():
    with st.sidebar:
        st.title("üå± SEMENTE FRAME")
        st.caption("Status: Conectado ao N√∫cleo")
        st.divider()
        # AQUI MUDOU: O usu√°rio s√≥ v√™ o upload, nada de chaves.
        file = st.file_uploader("Carregar Base de Dados (CSV)", type=["csv"])
        st.info("üîí Ambiente Seguro e Criptografado")

    if file:
        if "df" not in st.session_state:
            st.session_state.df = pd.read_csv(file)
            st.session_state.brain = SementeBrain() # O Brain pega as chaves sozinho
            st.session_state.ctx = st.session_state.brain.get_summary(st.session_state.df)
            st.session_state.msgs = [{"role": "assistant", "content": "Ol√°! Sou o Ruffeil. Seus dados foram processados com seguran√ßa. Como posso ajudar?"}]

        # Hist√≥rico
        for msg in st.session_state.msgs:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

        # Chat
        if prompt := st.chat_input("Pergunte ao Semente Frame..."):
            st.session_state.msgs.append({"role": "user", "content": prompt})
            st.chat_message("user").markdown(prompt)
            
            with st.spinner("Processando..."):
                resp = st.session_state.brain.ask_gpt(prompt, st.session_state.ctx)
                st.session_state.msgs.append({"role": "assistant", "content": resp})
                st.chat_message("assistant").markdown(resp)

        # Relat√≥rio
        st.divider()
        if st.button("Gerar Relat√≥rio T√©cnico"):
            with st.spinner("Gerando an√°lise executiva..."):
                rep = st.session_state.brain.get_report(st.session_state.ctx)
                with st.expander("üìÑ Ver Relat√≥rio Completo", expanded=True):
                    st.markdown(rep)
    else:
        st.markdown("<br><h1 style='text-align: center'>Bem-vindo ao SEMENTE FRAME üå±</h1>", unsafe_allow_html=True)
        st.markdown("<p style='text-align: center'>Fa√ßa o upload do CSV para iniciar a consultoria autom√°tica.</p>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
